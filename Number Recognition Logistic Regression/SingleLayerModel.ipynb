{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287e7877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c69a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root = 'data/' , download=True, transform = transforms.ToTensor())\n",
    "test_dataset = MNIST(root = 'data/' , train = False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d5aba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(index):\n",
    "    image , label = dataset[index]\n",
    "    plt.imshow(image.reshape(-1,28) , cmap='gray')\n",
    "    print('Label : ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b7447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf4cc2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds , val_ds = random_split(dataset , [50000,10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55f8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds , batch_size , shuffle=True)\n",
    "val_loader = DataLoader(val_ds , batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7289a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28 #size of each image\n",
    "output_classes = 10 # 10 different output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe1e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curiosity(title = \"Initial\"):\n",
    "    print(title)\n",
    "    print(\"Model Weights\")\n",
    "    print(model.linear.weight)\n",
    "    print(\"Model weights.grad\")\n",
    "    print(model.linear.weight.grad)\n",
    "    print(\"Model Bias\")\n",
    "    print(model.linear.bias)\n",
    "    print(\"Model bias.grad\")\n",
    "    print(model.linear.bias.grad)\n",
    "\n",
    "def fit(model , lr , epochs , train_loader , val_loader, opt_fun=torch.optim.SGD):\n",
    "    \n",
    "    optimizer = opt_fun(model.parameters() , lr)\n",
    "    history = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model , val_loader)\n",
    "        model.epoch_end(i , result)\n",
    "        history.append(result)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c88e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs , labels):\n",
    "    _,preds = torch.max(outputs,dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21026fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model , val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f5fdc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size , output_classes)\n",
    "        \n",
    "    def forward(self,xb):\n",
    "        xb = xb.reshape(-1,784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self,batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch):\n",
    "        images,labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        acc = accuracy(out,labels)\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self,outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(\n",
    "            batch_accs).mean()\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f93b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ecf8dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial\n",
      "Model Weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.0339,  0.0085,  0.0253,  ...,  0.0051, -0.0170,  0.0116],\n",
      "        [ 0.0116,  0.0218, -0.0114,  ..., -0.0318, -0.0256, -0.0357],\n",
      "        [-0.0324, -0.0302, -0.0312,  ...,  0.0158, -0.0224, -0.0003],\n",
      "        ...,\n",
      "        [-0.0160,  0.0136, -0.0098,  ...,  0.0120, -0.0190, -0.0161],\n",
      "        [-0.0301, -0.0011,  0.0343,  ...,  0.0140,  0.0315,  0.0322],\n",
      "        [-0.0013,  0.0046, -0.0206,  ...,  0.0300, -0.0051, -0.0158]],\n",
      "       requires_grad=True)\n",
      "Model weights.grad\n",
      "None\n",
      "Model Bias\n",
      "Parameter containing:\n",
      "tensor([-0.0333,  0.0088, -0.0188, -0.0101, -0.0331,  0.0086, -0.0089,  0.0060,\n",
      "        -0.0017, -0.0014], requires_grad=True)\n",
      "Model bias.grad\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "curiosity(\"Initial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "691792b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 2.2665, val_acc: 0.1613\n",
      "Epoch [1], val_loss: 2.1850, val_acc: 0.3215\n",
      "Epoch [2], val_loss: 2.1094, val_acc: 0.4794\n",
      "Epoch [3], val_loss: 2.0387, val_acc: 0.5768\n",
      "Epoch [4], val_loss: 1.9724, val_acc: 0.6355\n",
      "Epoch [5], val_loss: 1.9099, val_acc: 0.6714\n",
      "Epoch [6], val_loss: 1.8510, val_acc: 0.6970\n",
      "Epoch [7], val_loss: 1.7955, val_acc: 0.7144\n",
      "Epoch [8], val_loss: 1.7432, val_acc: 0.7268\n",
      "Epoch [9], val_loss: 1.6938, val_acc: 0.7359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 2.2665164470672607, 'val_acc': 0.1613256335258484},\n",
       " {'val_loss': 2.185014486312866, 'val_acc': 0.32145699858665466},\n",
       " {'val_loss': 2.109426498413086, 'val_acc': 0.4793988764286041},\n",
       " {'val_loss': 2.038749933242798, 'val_acc': 0.5768312215805054},\n",
       " {'val_loss': 1.9723724126815796, 'val_acc': 0.6355493664741516},\n",
       " {'val_loss': 1.909888744354248, 'val_acc': 0.6713773608207703},\n",
       " {'val_loss': 1.8510171175003052, 'val_acc': 0.696954607963562},\n",
       " {'val_loss': 1.795513391494751, 'val_acc': 0.7143710255622864},\n",
       " {'val_loss': 1.7431600093841553, 'val_acc': 0.7268112897872925},\n",
       " {'val_loss': 1.693786382675171, 'val_acc': 0.7358678579330444}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model , 1e-4 , 10 , train_loader , val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c19ac6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.6472, val_acc: 0.7451\n",
      "Epoch [1], val_loss: 1.6032, val_acc: 0.7529\n",
      "Epoch [2], val_loss: 1.5617, val_acc: 0.7596\n",
      "Epoch [3], val_loss: 1.5226, val_acc: 0.7652\n",
      "Epoch [4], val_loss: 1.4856, val_acc: 0.7700\n",
      "Epoch [5], val_loss: 1.4506, val_acc: 0.7742\n",
      "Epoch [6], val_loss: 1.4176, val_acc: 0.7787\n",
      "Epoch [7], val_loss: 1.3863, val_acc: 0.7813\n",
      "Epoch [8], val_loss: 1.3567, val_acc: 0.7845\n",
      "Epoch [9], val_loss: 1.3286, val_acc: 0.7883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.6472069025039673, 'val_acc': 0.7451233863830566},\n",
       " {'val_loss': 1.6032404899597168, 'val_acc': 0.752886176109314},\n",
       " {'val_loss': 1.5617460012435913, 'val_acc': 0.7595541477203369},\n",
       " {'val_loss': 1.5225803852081299, 'val_acc': 0.7652269005775452},\n",
       " {'val_loss': 1.485579252243042, 'val_acc': 0.7700039744377136},\n",
       " {'val_loss': 1.4506185054779053, 'val_acc': 0.7741839289665222},\n",
       " {'val_loss': 1.4175645112991333, 'val_acc': 0.7786624431610107},\n",
       " {'val_loss': 1.3862861394882202, 'val_acc': 0.7813495397567749},\n",
       " {'val_loss': 1.3566724061965942, 'val_acc': 0.784534215927124},\n",
       " {'val_loss': 1.3286198377609253, 'val_acc': 0.7883160710334778}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model , 1e-4 , 10 , train_loader , val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b0c3d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.3020, val_acc: 0.7912\n",
      "Epoch [1], val_loss: 1.2768, val_acc: 0.7931\n",
      "Epoch [2], val_loss: 1.2528, val_acc: 0.7952\n",
      "Epoch [3], val_loss: 1.2300, val_acc: 0.7978\n",
      "Epoch [4], val_loss: 1.2083, val_acc: 0.8000\n",
      "Epoch [5], val_loss: 1.1877, val_acc: 0.8024\n",
      "Epoch [6], val_loss: 1.1680, val_acc: 0.8042\n",
      "Epoch [7], val_loss: 1.1492, val_acc: 0.8060\n",
      "Epoch [8], val_loss: 1.1313, val_acc: 0.8079\n",
      "Epoch [9], val_loss: 1.1142, val_acc: 0.8100\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(model , 1e-4 , 10 , train_loader , val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ff82ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    print(img.shape)\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60c1f046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image(test_dataset[56][0] , model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a787d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
